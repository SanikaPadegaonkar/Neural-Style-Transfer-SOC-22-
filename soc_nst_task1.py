# -*- coding: utf-8 -*-
"""SOC_NST_Task1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w-0CQGM9lZIJM8yLTll_sLkXNX0FQgbG
"""

!pip install transformers

!pip install datasets

import transformers
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import seaborn as sns
from IPython.display import display
import matplotlib.pyplot as plt
import tensorflow as tf
import torch
from datasets import load_dataset

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
n_gpu = torch.cuda.device_count()
torch.cuda.get_device_name(0)

#uploading the datasets
from google.colab import files
uploaded=files.upload()
df_train=pd.read_csv('train.csv')
df_test=pd.read_csv('test.csv')

#df_train=load_dataset("csv",data_files="train.csv")
#df_train.set_format(type='pd')
#df_test=load_dataset("csv",data_files="test.csv")
#df_test.set_format(type='pd')
#print(df_train)

df_train,df_validate=train_test_split(df_train,test_size=0.2,random_state=42) #why is random state used? 
print(df_train)
print(df_test)

authors=df_train['author'].unique()
print(authors)

sns.countplot('author',data=df_train)
plt.title('train')
plt.show()
sns.countplot('author',data=df_validate)
plt.title('validate')
plt.show()

df_train['length']=df_train.text.str.count(' ')
df_validate['length']=df_validate.text.str.count(' ')
print(df_train.head())
print(df_validate.head())

print("Text length description for ", authors[0])
print(df_train[df_train['author']==authors[0]]['length'].describe())
print("Text length description for ", authors[1])
print(df_train[df_train['author']==authors[1]]['length'].describe())
print("Text length description for ", authors[2])
print(df_train[df_train['author']==authors[2]]['length'].describe())

"""We observe that the maximum text length is 860 words for author MWS.\
Let's see how many texts have length 860 in the entire train dataset. 
"""

print(df_train[df_train['length']==860])

"""Let's see what this 860 word text is"""

print(df_train.text[9215]) #DOUBT

sns.boxplot(x='author',y='length',data=df_train)

from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")

from transformers.utils.dummy_pt_objects import ElectraForSequenceClassification
for author in authors:
  print("Author:",author,"->Label:",(np.where(authors==author))[0][0])


#for index in print(df_train[df_train['author']==authors[0]]):
labels=[]
for index in df_train.index:
  if df_train.author[index]==authors[0]:
    labels.append(0)
  if df_train.author[index]==authors[1]:
    labels.append(1)
  if df_train.author[index]==authors[2]:
    labels.append(2)
 
df_train['labels']=labels

labels=[]
for index in df_validate.index:
  if df_validate.author[index]==authors[0]:
    labels.append(0)
  if df_validate.author[index]==authors[1]:
    labels.append(1)
  if df_validate.author[index]==authors[2]:
    labels.append(2)
 
df_validate['labels']=labels
#print(df_train)
df_train_final=(df_train.drop(columns=['id','author','length'],inplace=False)).set_index('text')
print(df_train_final)
df_validate_final=(df_validate.drop(columns=['id','author','length'],inplace=False)).set_index('text')
print(df_validate_final)

df_train_final.to_csv('df_train_final')
df_validate_final.to_csv('df_validate_final')

train=load_dataset("csv",data_files="df_train_final")
#df_train.set_format(type='pd')
validate=load_dataset("csv",data_files="df_validate_final")
#df_test.set_format(type='pd')
#print(df_train)
print(train)

#train=[]
#for index in df_train.index:
 #train_dict={}
 #train_dict['label']=df_train.labels[index]
 #train_dict['text']=df_train.text[index]
 #train.append(train_dict)
#print(train)
#validate=[]
#for index in df_validate.index:
 # validate_dict={}
  #validate_dict['label']=df_validate.labels[index]
  #validate_dict['text']=df_validate.text[index]
  #validate.append(validate_dict)
#def preprocess_function(examples):
    #return tokenizer(examples["text"], truncation=True)

#dataset={'train':train,'validate':validate}

def preprocess_function(examples):
    return tokenizer(examples["text"], truncation=True)

tokenized_df_train = train.map(preprocess_function, batched=True)
tokenized_df_validate = validate.map(preprocess_function, batched=True)

from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

!pip install seqeval

from datasets import load_metric

metric = load_metric("seqeval")

def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)

    all_metrics = metric.compute(predictions=predictions, references=labels)
    return {
        "precision": all_metrics["overall_precision"],
        "recall": all_metrics["overall_recall"],
        "f1": all_metrics["overall_f1"],
        "accuracy": all_metrics["overall_accuracy"],
    }

from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer
label_names=authors
id2label = {str(i): label for i, label in enumerate(label_names)}
label2id = {v: k for k, v in id2label.items()}
model = AutoModelForSequenceClassification.from_pretrained("distilbert-base-uncased", num_labels=3,id2label=id2label, label2id=label2id)

from huggingface_hub import notebook_login

notebook_login()

training_args = TrainingArguments(
    output_dir="./results",
    #'finetuned-distilbert-base-uncased',
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    #push_to_hub=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_df_train['train'],
    eval_dataset=tokenized_df_validate['train'],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    data_collator=data_collator,
)

trainer.train()

"""Doubt: push_to_hub=True not working.\
Error: You don't have a right to create models under this namespace.
"""

df_test_final=(df_test.drop(columns=['id'],inplace=False)).set_index('text')
print(df_test_final)
df_test_final.to_csv("df_test_final")
test=load_dataset("csv",data_files="df_test_final")
print(test)
tokenized_df_test = test.map(preprocess_function, batched=True)
print(tokenized_df_test)

predictions2 = trainer.predict(tokenized_df_validate['train'])
print(predictions2)
preds2 = np.argmax(predictions2.predictions, axis=-1)
#compute_metrics([predictions2.predictions.tolist(),predictions2.label_ids.tolist()])
metric.compute(predictions=preds2.tolist(), references=predictions2.label_ids.tolist())

predictions = trainer.predict(tokenized_df_test['train'])
#print(predictions)
#NO label_ids as we don't have the authors in the test set so we don't have any references to compare our predictions to
preds = np.argmax(predictions.predictions, axis=-1)
print(preds)
df_test_out=df_test_final.reset_index()
pred_authors=[]
for pred in preds:
  if pred==0:
    pred_authors.append(authors[0])
  elif pred==1:
    pred_authors.append(authors[1])
  elif pred==2:
    pred_authors.append(authors[2])

df_test_out['Predicted Authors']=pred_authors
print(df_test_out)
df_test_out.to_csv('predicted_authors')
  
#compute_metrics([predictions.predictions,predictions.label_ids])